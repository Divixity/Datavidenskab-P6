{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "def table_scraper(station, start_date, end_date):\n",
    "    current_date = start_date\n",
    "    search_url = 'https://www.wunderground.com/history/daily/{}/date/{}-{}-{}'\n",
    "\n",
    "    while current_date < end_date:\n",
    "        format_search_url = search_url.format('K'+station, current_date.year, current_date.month, current_date.day)\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(format_search_url)\n",
    "        # Makes sure all tables are loaded\n",
    "        table = WebDriverWait(driver,20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table\")))[-1]\n",
    "\n",
    "        # Reads the correct html table, and selects rows and cols of interest\n",
    "        _df = pd.read_html(table.get_attribute('outerHTML'))[0].dropna()[[\"Time\", \"Condition\"]]\n",
    "        _df[\"Date\"] = current_date\n",
    "\n",
    "        if start_date == current_date:\n",
    "            _df.to_csv(f'{station}_{start_date.year}_{end_date.year}.csv', header=True, index=False, mode=\"w\")\n",
    "        else:\n",
    "            _df.to_csv(f'{station}_{start_date.year}_{end_date.year}.csv', header=False, index=False, mode=\"a\")\n",
    "\n",
    "        current_date += timedelta(days=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "location = 'GAI'\n",
    "start = datetime(year=2015, month=2, day=1)\n",
    "end = datetime(year=2016, month=2, day=1)\n",
    "\n",
    "table_scraper(location, start, end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "def table_cleaning(table):\n",
    "    _df = pd.read_csv(table)\n",
    "\n",
    "    _df[\"Time\"] = pd.to_datetime(_df[\"Date\"] + \" \" + _df[\"Time\"], format=\"%Y-%m-%d %I:%M %p\").dt.floor('h')\n",
    "    del _df[\"Date\"]\n",
    "\n",
    "    _df[\"Time\"][_df[\"Time\"].dt.hour == 0] += timedelta(days=1)\n",
    "\n",
    "    _df = _df.groupby([\"Time\"])[\"Condition\"].agg(pd.Series.mode).reset_index()\n",
    "\n",
    "    rank = {\"Fair\": 1, \"Partly Cloudy\": 2, \"Mostly Cloudy\": 3, \"Cloudy\": 4, \"Thunder\": 5}\n",
    "    for idx, row in _df.iterrows():\n",
    "        if isinstance(_df[\"Condition\"][idx], np.ndarray):\n",
    "            _df.at[idx, \"Condition\"] = [con.replace(\" / Windy\", \"\").replace(\" in the Vicinity\", \"\") for con in _df[\"Condition\"][idx]]\n",
    "            _df.at[idx, \"Condition\"] = sorted(_df[\"Condition\"][idx], key = lambda ele: rank[ele])[len(_df[\"Condition\"][idx]) // 2]\n",
    "\n",
    "        elif isinstance(_df[\"Condition\"][idx], str):\n",
    "            _df.at[idx, \"Condition\"] = _df[\"Condition\"][idx].replace(\" / Windy\", \"\").replace(\" in the Vicinity\", \"\")\n",
    "\n",
    "    _df.to_csv(table, header=True, index=False, mode=\"w\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/w3ctvjn94jn89w856x4xh8zc0000gn/T/ipykernel_92951/1214078264.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df[\"Time\"][_df[\"Time\"].dt.hour == 0] += timedelta(days=1)\n"
     ]
    }
   ],
   "source": [
    "table_cleaning(\"GAI_2015_2016.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}