{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/w3ctvjn94jn89w856x4xh8zc0000gn/T/ipykernel_29716/23897791.py:16: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/heede/Downloads/household_power_consumption.txt', delimiter=';')\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Date      Time Global_active_power Global_reactive_power  \\\n0        16/12/2006  17:24:00               4.216                 0.418   \n1        16/12/2006  17:25:00               5.360                 0.436   \n2        16/12/2006  17:26:00               5.374                 0.498   \n3        16/12/2006  17:27:00               5.388                 0.502   \n4        16/12/2006  17:28:00               3.666                 0.528   \n...             ...       ...                 ...                   ...   \n2075254  26/11/2010  20:58:00               0.946                   0.0   \n2075255  26/11/2010  20:59:00               0.944                   0.0   \n2075256  26/11/2010  21:00:00               0.938                   0.0   \n2075257  26/11/2010  21:01:00               0.934                   0.0   \n2075258  26/11/2010  21:02:00               0.932                   0.0   \n\n         Voltage Global_intensity Sub_metering_1 Sub_metering_2  \\\n0        234.840           18.400          0.000          1.000   \n1        233.630           23.000          0.000          1.000   \n2        233.290           23.000          0.000          2.000   \n3        233.740           23.000          0.000          1.000   \n4        235.680           15.800          0.000          1.000   \n...          ...              ...            ...            ...   \n2075254   240.43              4.0            0.0            0.0   \n2075255    240.0              4.0            0.0            0.0   \n2075256   239.82              3.8            0.0            0.0   \n2075257    239.7              3.8            0.0            0.0   \n2075258   239.55              3.8            0.0            0.0   \n\n         Sub_metering_3  \n0                  17.0  \n1                  16.0  \n2                  17.0  \n3                  17.0  \n4                  17.0  \n...                 ...  \n2075254             0.0  \n2075255             0.0  \n2075256             0.0  \n2075257             0.0  \n2075258             0.0  \n\n[2075259 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Global_active_power</th>\n      <th>Global_reactive_power</th>\n      <th>Voltage</th>\n      <th>Global_intensity</th>\n      <th>Sub_metering_1</th>\n      <th>Sub_metering_2</th>\n      <th>Sub_metering_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16/12/2006</td>\n      <td>17:24:00</td>\n      <td>4.216</td>\n      <td>0.418</td>\n      <td>234.840</td>\n      <td>18.400</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16/12/2006</td>\n      <td>17:25:00</td>\n      <td>5.360</td>\n      <td>0.436</td>\n      <td>233.630</td>\n      <td>23.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16/12/2006</td>\n      <td>17:26:00</td>\n      <td>5.374</td>\n      <td>0.498</td>\n      <td>233.290</td>\n      <td>23.000</td>\n      <td>0.000</td>\n      <td>2.000</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16/12/2006</td>\n      <td>17:27:00</td>\n      <td>5.388</td>\n      <td>0.502</td>\n      <td>233.740</td>\n      <td>23.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16/12/2006</td>\n      <td>17:28:00</td>\n      <td>3.666</td>\n      <td>0.528</td>\n      <td>235.680</td>\n      <td>15.800</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2075254</th>\n      <td>26/11/2010</td>\n      <td>20:58:00</td>\n      <td>0.946</td>\n      <td>0.0</td>\n      <td>240.43</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2075255</th>\n      <td>26/11/2010</td>\n      <td>20:59:00</td>\n      <td>0.944</td>\n      <td>0.0</td>\n      <td>240.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2075256</th>\n      <td>26/11/2010</td>\n      <td>21:00:00</td>\n      <td>0.938</td>\n      <td>0.0</td>\n      <td>239.82</td>\n      <td>3.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2075257</th>\n      <td>26/11/2010</td>\n      <td>21:01:00</td>\n      <td>0.934</td>\n      <td>0.0</td>\n      <td>239.7</td>\n      <td>3.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2075258</th>\n      <td>26/11/2010</td>\n      <td>21:02:00</td>\n      <td>0.932</td>\n      <td>0.0</td>\n      <td>239.55</td>\n      <td>3.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2075259 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "# read the dataset into python\n",
    "df = pd.read_csv('/Users/heede/Downloads/household_power_consumption.txt', delimiter=';')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns after removing missing values: (2049280, 2)\n",
      "The time series starts from:  2006-12-16 17:24:00\n",
      "The time series ends on:  2010-12-11 23:59:00\n",
      "CPU times: user 1min 2s, sys: 424 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This code is copied from https://towardsdatascience.com/time-series-analysis-visualization-forecasting-with-lstm-77a905180eba\n",
    "# with a few minor changes.\n",
    "#\n",
    "df['date_time'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "df['Global_active_power'] = pd.to_numeric(df['Global_active_power'], errors='coerce')\n",
    "df = df.dropna(subset=['Global_active_power'])\n",
    "\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "\n",
    "df = df.loc[:, ['date_time', 'Global_active_power']]\n",
    "df.sort_values('date_time', inplace=True, ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print('Number of rows and columns after removing missing values:', df.shape)\n",
    "print('The time series starts from: ', df['date_time'].min())\n",
    "print('The time series ends on: ', df['date_time'].max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dates: 2010-12-05 00:00:00 to 2010-12-11 23:59:00\n",
      "Validation dates: 2010-11-21 00:00:00 to 2010-12-04 23:59:00\n",
      "Train dates: 2006-12-16 17:24:00 to 2010-11-20 23:59:00\n"
     ]
    }
   ],
   "source": [
    "# Split into training, validation and test datasets.\n",
    "# Since it's timeseries we should do it by date.\n",
    "test_cutoff_date = df['date_time'].max() - timedelta(days=7)\n",
    "val_cutoff_date = test_cutoff_date - timedelta(days=14)\n",
    "\n",
    "df_test = df[df['date_time'] > test_cutoff_date]\n",
    "df_val = df[(df['date_time'] > val_cutoff_date) & (df['date_time'] <= test_cutoff_date)]\n",
    "df_train = df[df['date_time'] <= val_cutoff_date]\n",
    "\n",
    "#check out the datasets\n",
    "print('Test dates: {} to {}'.format(df_test['date_time'].min(), df_test['date_time'].max()))\n",
    "print('Validation dates: {} to {}'.format(df_val['date_time'].min(), df_val['date_time'].max()))\n",
    "print('Train dates: {} to {}'.format(df_train['date_time'].min(), df_train['date_time'].max()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Goal of the model:\n",
    "#  Predict Global_active_power at a specified time in the future.\n",
    "#   Eg. We want to predict how much Global_active_power will be ten minutes from now.\n",
    "#       We can use all the values from t-1, t-2, t-3, .... t-history_length to predict t+10\n",
    "\n",
    "\n",
    "def create_ts_files(dataset,\n",
    "                    start_index,\n",
    "                    end_index,\n",
    "                    history_length,\n",
    "                    step_size,\n",
    "                    target_step,\n",
    "                    num_rows_per_file,\n",
    "                    data_folder):\n",
    "    assert step_size > 0\n",
    "    assert start_index >= 0\n",
    "\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    time_lags = sorted(range(target_step+1, target_step+history_length+1, step_size), reverse=True)\n",
    "    col_names = [f'x_lag{i}' for i in time_lags] + ['y']\n",
    "    start_index = start_index + history_length\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_step\n",
    "\n",
    "    rng = range(start_index, end_index)\n",
    "    num_rows = len(rng)\n",
    "    num_files = math.ceil(num_rows/num_rows_per_file)\n",
    "\n",
    "    # for each file.\n",
    "    print(f'Creating {num_files} files.')\n",
    "    for i in range(num_files):\n",
    "        filename = f'{data_folder}/ts_file{i}.pkl'\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'{filename}')\n",
    "\n",
    "        # get the start and end indices.\n",
    "        ind0 = i*num_rows_per_file\n",
    "        ind1 = min(ind0 + num_rows_per_file, end_index)\n",
    "        data_list = []\n",
    "\n",
    "        # j in the current timestep. Will need j-n to j-1 for the history. And j + target_step for the target.\n",
    "        for j in range(ind0, ind1):\n",
    "            indices = range(j-1, j-history_length-1, -step_size)\n",
    "            data = dataset[sorted(indices) + [j+target_step]]\n",
    "\n",
    "            # append data to the list.\n",
    "            data_list.append(data)\n",
    "\n",
    "        df_ts = pd.DataFrame(data=data_list, columns=col_names)\n",
    "        df_ts.to_pickle(filename)\n",
    "\n",
    "    return len(col_names)-1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 1.86 ms, total: 14 ms\n",
      "Wall time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "global_active_power = df_train['Global_active_power'].values\n",
    "\n",
    "# Scaled to work with Neural networks.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "global_active_power_scaled = scaler.fit_transform(global_active_power.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_length = 7*24*60  # The history length in minutes.\n",
    "step_size = 10  # The sampling rate of the history. Eg. If step_size = 1, then values from every minute will be in the history.\n",
    "#                                       If step size = 10 then values every 10 minutes will be in the history.\n",
    "target_step = 10  # The time step in the future to predict. Eg. If target_step = 0, then predict the next timestep after the end of the history period.\n",
    "#                                             If target_step = 10 then predict 10 timesteps the next timestep (11 minutes after the end of history).\n",
    "\n",
    "# The csv creation returns the number of rows and number of features. We need these values below.\n",
    "num_timesteps = create_ts_files(global_active_power_scaled,\n",
    "                                start_index=0,\n",
    "                                end_index=None,\n",
    "                                history_length=history_length,\n",
    "                                step_size=step_size,\n",
    "                                target_step=target_step,\n",
    "                                num_rows_per_file=128*100,\n",
    "                                data_folder='ts_data')\n",
    "#\n",
    "# # I found that the easiest way to do time series with tensorflow is by creating pandas files with the lagged time steps (eg. x{t-1}, x{t-2}...) and\n",
    "# # the value to predict y = x{t+n}. We tried doing it using TFRecords, but that API is not very intuitive and lacks working examples for time series.\n",
    "# # The resulting file using these parameters is over 17GB. If history_length is increased, or  step_size is decreased, it could get much bigger.\n",
    "# # Hard to fit into laptop memory, so need to use other means to load the data from the hard drive."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "ts_folder = 'ts_data'\n",
    "filename_format = 'ts_file{}.pkl'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#\n",
    "# So we can handle loading the data in chunks from the hard drive instead of having to load everything into memory.\n",
    "#\n",
    "# The reason we want to do this is so we can do custom processing on the data that we are feeding into the LSTM.\n",
    "# LSTM requires a certain shape and it is tricky to get it right.\n",
    "#\n",
    "class TimeSeriesLoader:\n",
    "    def __init__(self, ts_folder, filename_format):\n",
    "        self.ts_folder = ts_folder\n",
    "\n",
    "        # find the number of files.\n",
    "        i = 0\n",
    "        file_found = True\n",
    "        while file_found:\n",
    "            filename = self.ts_folder + '/' + filename_format.format(i)\n",
    "            file_found = os.path.exists(filename)\n",
    "            if file_found:\n",
    "                i += 1\n",
    "\n",
    "        self.num_files = i\n",
    "        self.files_indices = np.arange(self.num_files)\n",
    "        self.shuffle_chunks()\n",
    "\n",
    "    def num_chunks(self):\n",
    "        return self.num_files\n",
    "\n",
    "    def get_chunk(self, idx):\n",
    "        assert (idx >= 0) and (idx < self.num_files)\n",
    "\n",
    "        ind = self.files_indices[idx]\n",
    "        filename = self.ts_folder + '/' + filename_format.format(ind)\n",
    "        df_ts = pd.read_pickle(filename)\n",
    "        num_records = len(df_ts.index)\n",
    "\n",
    "        features = df_ts.drop('y', axis=1).values\n",
    "        target = df_ts['y'].values\n",
    "\n",
    "        # reshape for input into LSTM. Batch major format.\n",
    "        features_batchmajor = np.array(features).reshape(num_records, -1, 1)\n",
    "        return features_batchmajor, target\n",
    "\n",
    "    # this shuffles the order the chunks will be outputted from get_chunk.\n",
    "    def shuffle_chunks(self):\n",
    "        np.random.shuffle(self.files_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "tss = TimeSeriesLoader(ts_folder, filename_format)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 13:36:44.993557: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-29 13:36:44.993735: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    }
   ],
   "source": [
    "# Create the Keras model.\n",
    "# Use hyperparameter optimization if you have the time.\n",
    "\n",
    "ts_inputs = tf.keras.Input(shape=(num_timesteps, 1))\n",
    "\n",
    "# units=10 -> The cell and hidden states will be of dimension 10.\n",
    "#             The number of parameters that need to be trained = 4*units*(units+2)\n",
    "x = layers.LSTM(units=10)(ts_inputs)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 13:37:05.010749: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-29 13:37:05.308299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-29 13:37:05.474900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-29 13:37:09.889632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 38s 252ms/step - loss: 0.0024 - mse: 0.0024\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0062 - mse: 0.0062\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0070 - mse: 0.0070\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0065 - mse: 0.0065\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0019 - mse: 0.0019\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0054 - mse: 0.0054\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0056 - mse: 0.0056\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0049 - mse: 0.0049\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0028 - mse: 0.0028\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0053 - mse: 0.0053\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0033 - mse: 0.0033\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0053 - mse: 0.0053\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0019 - mse: 0.0019\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0056 - mse: 0.0056\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0078 - mse: 0.0078\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0038 - mse: 0.0038\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0014 - mse: 0.0014\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0029 - mse: 0.0029\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0060 - mse: 0.0060\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0029 - mse: 0.0029\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0068 - mse: 0.0068\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0033 - mse: 0.0033\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0027 - mse: 0.0027\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0020 - mse: 0.0020\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0061 - mse: 0.0061\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0053 - mse: 0.0053\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0033 - mse: 0.0033\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0030 - mse: 0.0030\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0032 - mse: 0.0032\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0028 - mse: 0.0028\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0030 - mse: 0.0030\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0029 - mse: 0.0029\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0028 - mse: 0.0028\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0028 - mse: 0.0028\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0033 - mse: 0.0033\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0015 - mse: 0.0015\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0032 - mse: 0.0032\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0025 - mse: 0.0025\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0038 - mse: 0.0038\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0054 - mse: 0.0054\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0054 - mse: 0.0054\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 4.7981e-04 - mse: 4.7981e-04\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0029 - mse: 0.0029\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0038 - mse: 0.0038\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0029 - mse: 0.0029\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0056 - mse: 0.0056\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0029 - mse: 0.0029\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0058 - mse: 0.0058\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0033 - mse: 0.0033\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0028 - mse: 0.0028\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0070 - mse: 0.0070\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0038 - mse: 0.0038\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0032 - mse: 0.0032\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0031 - mse: 0.0031\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 0.0030 - mse: 0.0030\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0062 - mse: 0.0062\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0018 - mse: 0.0018\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0032 - mse: 0.0032\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 0.0013 - mse: 0.0013\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0028 - mse: 0.0028\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0032 - mse: 0.0032\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0031 - mse: 0.0031\n",
      "CPU times: user 1h 36s, sys: 9min 59s, total: 1h 10min 36s\n",
      "Wall time: 1h 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train in batch sizes of 128.\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 1\n",
    "NUM_CHUNKS = tss.num_chunks()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('epoch #{}'.format(epoch))\n",
    "    for i in range(NUM_CHUNKS):\n",
    "        X, y = tss.get_chunk(i)\n",
    "\n",
    "        # model.fit does train the model incrementally. ie. Can call multiple times in batches.\n",
    "        # https://github.com/keras-team/keras/issues/4446\n",
    "        model.fit(x=X, y=y, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # shuffle the chunks so they're not in the same order next time around.\n",
    "    tss.shuffle_chunks()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 files.\n",
      "ts_val_data/ts_file0.pkl\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the validation set.\n",
    "#\n",
    "# Create the validation CSV like we did before with the training.\n",
    "global_active_power_val = df_val['Global_active_power'].values\n",
    "global_active_power_val_scaled = scaler.transform(global_active_power_val.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_length = 7*24*60  # The history length in minutes.\n",
    "step_size = 10  # The sampling rate of the history. Eg. If step_size = 1, then values from every minute will be in the history.\n",
    "#                                       If step size = 10 then values every 10 minutes will be in the history.\n",
    "target_step = 10  # The time step in the future to predict. Eg. If target_step = 0, then predict the next timestep after the end of the history period.\n",
    "#                                             If target_step = 10 then predict 10 timesteps the next timestep (11 minutes after the end of history).\n",
    "\n",
    "# The csv creation returns the number of rows and number of features. We need these values below.\n",
    "num_timesteps = create_ts_files(global_active_power_val_scaled,\n",
    "                                start_index=0,\n",
    "                                end_index=None,\n",
    "                                history_length=history_length,\n",
    "                                step_size=step_size,\n",
    "                                target_step=target_step,\n",
    "                                num_rows_per_file=128*100,\n",
    "                                data_folder='ts_val_data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 14:48:12.982546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-29 14:48:13.020589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mean squared error: 0.3720419510280685\n",
      "validation baseline mean squared error: 0.428345914375\n"
     ]
    }
   ],
   "source": [
    "# If we assume that the validation dataset can fit into memory we can do this.\n",
    "df_val_ts = pd.read_pickle('ts_val_data/ts_file0.pkl')\n",
    "\n",
    "\n",
    "features = df_val_ts.drop('y', axis=1).values\n",
    "features_arr = np.array(features)\n",
    "\n",
    "# reshape for input into LSTM. Batch major format.\n",
    "num_records = len(df_val_ts.index)\n",
    "features_batchmajor = features_arr.reshape(num_records, -1, 1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(features_batchmajor).reshape(-1, )\n",
    "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1 ,)\n",
    "\n",
    "y_act = df_val_ts['y'].values\n",
    "y_act = scaler.inverse_transform(y_act.reshape(-1, 1)).reshape(-1 ,)\n",
    "\n",
    "print('validation mean squared error: {}'.format(mean_squared_error(y_act, y_pred)))\n",
    "\n",
    "#baseline\n",
    "y_pred_baseline = df_val_ts['x_lag11'].values\n",
    "y_pred_baseline = scaler.inverse_transform(y_pred_baseline.reshape(-1, 1)).reshape(-1 ,)\n",
    "print('validation baseline mean squared error: {}'.format(mean_squared_error(y_act, y_pred_baseline)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}